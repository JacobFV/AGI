---
layout: post
title:  Meditating on AI
date:   2020-09-27
description: 
---


[Continual Prototype Evolution: Learning Online from Non-Stationary Data Streams](https://arxiv.org/abs/2009.00919) makes optimizaiton much faster in their demonstrated cases. I will look for internet implimentations in tensorflow, but I may have to write it myself. It looks worth the effort however. Also [Continual Prototype Evolution: Learning Online from Non-Stationary Data Streams](https://arxiv.org/abs/2009.00919) identifies the challange of nonstationarity. However, their problem is only with stationary nonstationarity, if you will. That is, they make random data stream transitions, but the datastreams themselves are consistant. Open ended learning is different though. It demands true continual learning. I believe that the graph agents if trianed on sufficently varied tasks with gradient optimization should learn to utilize the graph to make on-policy bahvior changes (gpt3 like in-context learning) without gradient updates. Gradient descent is like the womb, but once the agent becomes smarter, then it will learn to reach into its own code - even building datasets of exemplars for itself. Self-training may overlap supervised-training. This actually draws inspiration from the earlier [THE NEXT BIG THING(S) IN UNSUPERVISED MACHINE LEARNING: FIVE LESSONS FROM INFANT LEARNING](https://arxiv.org/abs/2009.08497) in letting the baby learn for itself while under the training of a 'parental' optimizer. (edit: I fogot to mention that Facebook's Blender chatbot also inspied this vein where it trains on the maximally certain data elements)

