# AI-Resources
A non-exhaustive collection of artificial intelligence resources. Please submit pull requests.

## Reinforcement Learning

### Agents
- [OpenAI Baselines](https://github.com/openai/baseline): "OpenAI Baselines is a set of high-quality implementations of reinforcement learning algorithms." Check out [implementations](https://github.com/openai/baselines/network/dependents?package_id=UGFja2FnZS01MDIzMjE5Mw%3D%3D).
- [plan2explore](https://github.com/ramanans1/plan2explore)

### Frameworks
- gym
- [Acme](https://github.com/deepmind/acme)
  > Acme is a library of reinforcement learning (RL) agents and agent building blocks. Acme strives to expose simple, efficient, and readable agents, that serve both as reference implementations of popular algorithms and as strong baselines, while still providing enough flexibility to do novel research. The design of Acme also attempts to provide multiple points of entry to the RL problem at differing levels of complexity.


### Environments
- [Control Suite](https://github.com/deepmind/dm_control)
  > The DeepMind Control Suite is a set of continuous control tasks with a standardised structure and interpretable rewards, intended to serve as performance benchmarks for reinforcement learning agents. The tasks are written in Python and powered by the MuJoCo physics engine, making them easy to use and modify. (https://arxiv.org/abs/1801.00690)
- Behavior Suite [(bsuite)](https://github.com/deepmind/bsuite)
  > `bsuite` is a collection of carefully-designed experiments
that investigate core capabilities of reinforcement learning (RL) agents with
two objectives. First, to collect clear, informative and scalable problems
that capture key issues in the design of general and efficient learning algorithms. Second, to study agent behaviour through their performance
on these shared benchmarks. (https://arxiv.org/abs/1908.03568)
- Arcade Learning Environment ([ALE](https://github.com/mgbellemare/Arcade-Learning-Environment)): Automatically benchmark agents on an array of video games.
  > interface to hundreds of Atari 2600 game environments, each one different, interesting, and designed to be a challenge for human players (https://jair.org/index.php/jair/article/view/10819)
- [Super Mario Bros](https://github.com/Kautenja/gym-super-mario-bros)
  > An OpenAI Gym environment for Super Mario Bros. & Super Mario Bros. 2 (Lost Levels) on The Nintendo Entertainment System (NES) using the nes-py emulator.
- [MalmoEnv](https://github.com/Microsoft/malmo/tree/master/MalmoEnv): MalmoEnv is an OpenAI "gym" Python Environment for Malmo/Minecraft, directly implemented Python to Java Minecraft.
> [DeepMind Lab](https://github.com/deepmind/lab) s a 3D learning environment based on id Software's Quake III Arena via ioquake3 and other open source software.
